
1) HazÄ±rlÄ±k â€” namespace ve storageclass kontrolÃ¼
# namespace oluÅŸtur
* kubectl create namespace monitoring

# cluster'Ä±n default storage class'Ä±nÄ± kontrol et (persistence kullanacaksan)
* kubectl get storageclass

2) Grafana Helm repo ekle ve gÃ¼ncelle
* helm repo add grafana https://grafana.github.io/helm-charts
* helm repo update

2) Grafana kurulumu (Helm ile)

AÅŸaÄŸÄ±daki komut, Grafanaâ€™yÄ± Helm chartâ€™Ä± kullanarak monitoring namespaceâ€™ine kurar.
Admin kullanÄ±cÄ± adÄ± ve ÅŸifresini sen belirliyorsun.
Service tipi NodePort olacak â€” bÃ¶ylece localhost veya minikube/Docker Desktop Ã¼zerinden kolayca eriÅŸebilirsin.

>Test / Ã–ÄŸrenme iÃ§in (persistence kapalÄ±)

helm install grafana grafana/grafana \
  --namespace monitoring \
  --set adminUser=admin \
  --set adminPassword='Sifre123!' \
  --set service.type=NodePort \
  --set persistence.enabled=false

â¡ï¸ Hafif, geÃ§ici kurulum.
Pod silinirse dashboard verileri de silinir.

>KalÄ±cÄ± kullanÄ±m / Prod ortamÄ± (persistence aÃ§Ä±k)

helm install grafana grafana/grafana \
  --namespace monitoring \
  --set adminUser=admin \
  --set adminPassword='Sifre123!' \
  --set service.type=NodePort \
  --set persistence.enabled=true \
  --set persistence.storageClassName=hostpath \
  --set persistence.size=1Gi

â¡ï¸ PVC kullanÄ±r, veriler disk Ã¼zerinde saklanÄ±r.

Pod yeniden baÅŸlasa da dashboardâ€™lar kaybolmaz.

	â€¢	adminUser â†’ giriÅŸ kullanÄ±cÄ± adÄ±
	â€¢	adminPassword â†’ giriÅŸ ÅŸifresi
	â€¢	service.type=NodePort â†’ local eriÅŸim kolaylÄ±ÄŸÄ±
	â€¢	persistence.enabled=true â†’ dashboard verileri kalÄ±cÄ± olur
	â€¢	storageClassName=hostpath â†’ senin storage classâ€™Ä±na uygun
	â€¢	persistence.size=10Gi â†’ 1GB PVC oluÅŸturur


4) Pod ve Servis durumlarÄ±nÄ± kontrol et

* kubectl get pods -n monitoring
* kubectl get svc -n monitoring

Ã¶rnek Ã§Ä±ktÄ±:
grafana   NodePort   10.96.184.232   <none>   80:31543/TCP   2m

Buradaki 31543 portunu not al.
TarayÄ±cÄ±dan ÅŸu ÅŸekilde eriÅŸebilirsin:

>http://localhost:31543

Alternatif olarak, port-forward komutuyla da eriÅŸebilirsin:
>kubectl port-forward svc/grafana -n monitoring 3000:80
# TarayÄ±cÄ±: http://localhost:3000



5) GiriÅŸ yap

TarayÄ±cÄ±da aÃ§tÄ±ÄŸÄ±nda kullanÄ±cÄ± adÄ± ve ÅŸifre ekranÄ± gelir:
	â€¢	KullanÄ±cÄ±: admin
	â€¢	Åifre: Sifre123!

EÄŸer ÅŸifreyi unuttuysan veya default chart kurduysan:

> kubectl get secret -n monitoring grafana -o jsonpath="{.data.admin-password}" | base64 --decode ; echo


###### ###### ####
# Ã–NEMLÄ° VALUES values.yaml local yapÄ±mÄ±za Ã§ekelim 
* helm show values grafana/grafana > my-values.yaml
# sadece values deÄŸerlerini gÃ¶reyim 
* helm get values grafana -n monitoring

# valuesde deÄŸiÅŸiklik iÃ§in 
a) Mevcut valuesâ€™u Ã§ek:
helm get values grafana -n monitoring -o yaml > current-values.yaml
b) DosyayÄ± dÃ¼zenle:
vim current-values.yaml
c) SMTP ayarlarÄ±nÄ± ekle:Ã¶rneÄŸin maile alert almak iÃ§in ?
smtp:
  enabled: true
  host: smtp.gmail.com:587
  user: ahmetcn2022@gmail.com
  password: "GMAIL_APP_PASSWORD"
  from_address: ahmetcn2022@gmail.com
  from_name: Grafana
  skip_verify: true
d) DeÄŸiÅŸikliÄŸi uygula:
helm upgrade grafana grafana/grafana -n monitoring -f current-values.yaml
>Bu, sadece deÄŸiÅŸtirdiÄŸin alanlarÄ± gÃ¼nceller. Grafana pod yeniden baÅŸlar.
----------------------------------------------------------------------------------

### 1ï¸âƒ£ Prometheusâ€™u Helm ile kur

Docker Desktop Kubernetes ortamÄ±na Prometheusâ€™u kurman gerekiyor:

* helm repo add prometheus-community https://prometheus-community.github.io/helm-charts

helm repo update

helm install prometheus prometheus-community/prometheus \
  --namespace monitoring \
  --create-namespace

Bu komut:
	â€¢	monitoring namespaceâ€™ini oluÅŸturur
	â€¢	Prometheus server ve node exporterâ€™Ä± kurar
	â€¢	Otomatik olarak metrik toplamaya baÅŸlar
	â€¢	--create-namespace â†’ eÄŸer namespace yoksa otomatik olarak oluÅŸturur


2ï¸âƒ£ Grafanaâ€™yÄ± Prometheusâ€™a baÄŸla

Grafanaâ€™yÄ± zaten kurmuÅŸtun, ÅŸimdi Prometheusâ€™u â€œdata sourceâ€ olarak ekleyelim 

YÃ¶ntem 1 â€” Grafana UI Ã¼zerinden (kolay yÃ¶ntem)
	1.	TarayÄ±cÄ±dan Grafanaâ€™yÄ± aÃ§:
	2.	Grafanaâ€™ya giriÅŸ yap (admin / Sifre123!)
	3.	â€œConnections â†’ Data Sources â†’ Add data sourceâ€ yolunu izle
	4.	â€œPrometheusâ€ seÃ§
	5.	URL kÄ±smÄ±na ÅŸunu yaz:
  * http://prometheus-server.monitoring.svc.cluster.local
  yada sadece 
  * http://prometheus-server
  6.â€œSave & Testâ€ de â†’ âœ… â€œData source is workingâ€ Ã§Ä±karsa tamamdÄ±r

3ï¸âƒ£ Pod metriklerini gÃ¶r

Åimdi Grafanaâ€™da:
	â€¢	â€œ+ Create â†’ Importâ€ bÃ¶lÃ¼mÃ¼ne gir
	â€¢	Dashboard ID olarak ÅŸunu yaz: 6417 (Kubernetes Cluster Monitoring)
	â€¢	â€œPrometheusâ€ datasÄ±nÄ± seÃ§
	â€¢	â€œImportâ€ de
    yada
    dashboard a gir saÄŸ Ã¼st kÃ¶ÅŸe new menÃ¼sÃ¼ oradan import tÄ±kla
    Dashboard ID olarak ÅŸunu yaz: 6417 (Kubernetes Cluster Monitoring)
	â€¢	â€œPrometheusâ€ datasÄ±nÄ± seÃ§
	â€¢	â€œImportâ€ de

Bu dashboardâ€™ta:
	â€¢	Pod CPU / RAM kullanÄ±mÄ±
	â€¢	Node performansÄ±
	â€¢	Namespace bazlÄ± pod grafikleri

                                                |

## FAVORÄ° DASHBOARD IM :)) K8S Dashboard :   15661

| **Kubernetes Cluster Monitoring (via Prome** | **6417**     | TÃ¼m cluster genelinde izleme: node, pod, namespace vb.         |
| **Kubernetes Monitoring Dashboard**          | < **12740**  >  | Kubernetes metriklerini pod/Ã§evre dÃ¼zeyinde detaylÄ± izleme     |
| **Kubernetes Views / Pods**                  | **15760**    | Pod seviyesinde detaylÄ± izleme iÃ§in â€œviewsâ€ tarzÄ± panel        |
| **Kubernetes All Pods**                      | **10676**    | TÃ¼m podâ€™larÄ± ve durumlarÄ±nÄ± hÄ±zlÄ±ca gÃ¶rmek iÃ§in hÄ±zlÄ± tablo tipi |
| **Kubernetes Views / Nodes List**            | **22153**    | Node listesini ve durumlarÄ±nÄ± izlemek iÃ§in Ã¶zel panel          |





# LÄ°STELE
1. TÃ¼m yÃ¼klÃ¼ Helm releaseâ€™lerini gÃ¶ster (namespace fark etmeksizin)
helm list -A

2. Belirli bir namespace iÃ§indeki releaseâ€™leri gÃ¶rmek iÃ§in
helm list -n monitoring
3. Helmâ€™in local cache (indirilen chartâ€™lar) klasÃ¶rÃ¼nÃ¼ gÃ¶rmek
helm env

# KALDIR

ğŸ§¹1. Helm releaseâ€™lerini kaldÄ±r

>helm uninstall grafana -n monitoring
>helm uninstall prometheus -n monitoring

Bu komutlar monitoring namespaceâ€™inden sadece Helm releaseâ€™lerini kaldÄ±rÄ±r,
ama PVC (PersistentVolumeClaim) gibi veriler kalabilir.


2. (Ä°steÄŸe baÄŸlÄ±) Namespaceâ€™i de sil

EÄŸer o namespace sadece bu iki uygulama iÃ§in oluÅŸturulduysa:

>kubectl delete namespace monitoring


3. Helm repolarÄ±nÄ± listele

Åu an ekli repolarÄ± gÃ¶rmek iÃ§in:

>helm repo list



4. Repoâ€™larÄ± kaldÄ±r

Ã‡Ä±ktÄ±daki isimlere gÃ¶re kaldÄ±r:

>   helm repo remove grafana
>   helm repo remove prometheus-community


5. (Opsiyonel) Local cache ve metadataâ€™yÄ± da temizle

helm repo remove stable
rm -rf ~/.cache/helm
rm -rf ~/.config/helm
rm -rf ~/.local/share/helm




# TÃœM BU KALDIRMA SÄ°LME Ä°ÅLEMLERÄ°NÄ° TEK BÄ°R .SH FÄ°LE Ä°LE GERÃ‡EKLEÅTÄ°RÄ°LEBÄ°LÄ°R 
# aynÄ± dizinde cleanup-monitoring.sh isminde yer almaktadÄ±r 
aÃ§Ä±klama:

Ã‡alÄ±ÅŸtÄ±rÄ±labilir hale getir:

chmod +x cleanup-monitoring.sh


Ã‡alÄ±ÅŸtÄ±r:

./cleanup-monitoring.sh



-------
<aynÄ± dizinde helm-reset.sh ile de hem prometheus grafanayÄ± sistemden kaldÄ±rÄ±rken
Cluster iÃ§inde helm e ait tÃ¼m yapÄ±larÄ± ns farkletmeksizin kaldÄ±rÄ±r.>
